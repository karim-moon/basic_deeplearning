{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#hidden node가 1개인 신경망\n",
    "x = np.matrix([[0,0], [0,1], [1,0], [1,1]])\n",
    "y = np.matrix([0, 1, 1, 0]).T\n",
    "\n",
    "\n",
    "weight = np.random.rand(2,1)\n",
    "\n",
    "lr = 1e-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0 loss : 1.0\n",
      "iteration : 1000 loss : 2.0\n",
      "iteration : 2000 loss : 2.0\n",
      "iteration : 3000 loss : 2.0\n",
      "iteration : 4000 loss : 2.0\n",
      "iteration : 5000 loss : 2.0\n",
      "iteration : 6000 loss : 2.0\n",
      "iteration : 7000 loss : 2.0\n",
      "iteration : 8000 loss : 2.0\n",
      "iteration : 9000 loss : 2.0\n",
      "iteration : 10000 loss : 2.0\n",
      "iteration : 11000 loss : 2.0\n",
      "iteration : 12000 loss : 2.0\n",
      "iteration : 13000 loss : 2.0\n",
      "iteration : 14000 loss : 2.0\n",
      "iteration : 15000 loss : 2.0\n",
      "iteration : 16000 loss : 2.0\n",
      "iteration : 17000 loss : 2.0\n",
      "iteration : 18000 loss : 2.0\n",
      "iteration : 19000 loss : 2.0\n",
      "iteration : 20000 loss : 2.0\n",
      "iteration : 21000 loss : 2.0\n",
      "iteration : 22000 loss : 2.0\n",
      "iteration : 23000 loss : 2.0\n",
      "iteration : 24000 loss : 2.0\n",
      "iteration : 25000 loss : 2.0\n",
      "iteration : 26000 loss : 2.0\n",
      "iteration : 27000 loss : 2.0\n",
      "iteration : 28000 loss : 2.0\n",
      "iteration : 29000 loss : 2.0\n",
      "iteration : 30000 loss : 2.0\n",
      "iteration : 31000 loss : 2.0\n",
      "iteration : 32000 loss : 2.0\n",
      "iteration : 33000 loss : 2.0\n",
      "iteration : 34000 loss : 2.0\n",
      "iteration : 35000 loss : 2.0\n",
      "iteration : 36000 loss : 2.0\n",
      "iteration : 37000 loss : 2.0\n",
      "iteration : 38000 loss : 2.0\n",
      "iteration : 39000 loss : 2.0\n",
      "iteration : 40000 loss : 2.0\n",
      "iteration : 41000 loss : 2.0\n",
      "iteration : 42000 loss : 2.0\n",
      "iteration : 43000 loss : 2.0\n",
      "iteration : 44000 loss : 2.0\n",
      "iteration : 45000 loss : 2.0\n",
      "iteration : 46000 loss : 2.0\n",
      "iteration : 47000 loss : 2.0\n",
      "iteration : 48000 loss : 2.0\n",
      "iteration : 49000 loss : 2.0\n",
      "iteration : 50000 loss : 2.0\n",
      "iteration : 51000 loss : 2.0\n",
      "iteration : 52000 loss : 2.0\n",
      "iteration : 53000 loss : 2.0\n",
      "iteration : 54000 loss : 2.0\n",
      "iteration : 55000 loss : 2.0\n",
      "iteration : 56000 loss : 2.0\n",
      "iteration : 57000 loss : 2.0\n",
      "iteration : 58000 loss : 2.0\n",
      "iteration : 59000 loss : 2.0\n",
      "iteration : 60000 loss : 2.0\n",
      "iteration : 61000 loss : 2.0\n",
      "iteration : 62000 loss : 2.0\n",
      "iteration : 63000 loss : 2.0\n",
      "iteration : 64000 loss : 2.0\n",
      "iteration : 65000 loss : 2.0\n",
      "iteration : 66000 loss : 2.0\n",
      "iteration : 67000 loss : 2.0\n",
      "iteration : 68000 loss : 2.0\n",
      "iteration : 69000 loss : 2.0\n",
      "iteration : 70000 loss : 2.0\n",
      "iteration : 71000 loss : 2.0\n",
      "iteration : 72000 loss : 2.0\n",
      "iteration : 73000 loss : 2.0\n",
      "iteration : 74000 loss : 2.0\n",
      "iteration : 75000 loss : 2.0\n",
      "iteration : 76000 loss : 2.0\n",
      "iteration : 77000 loss : 2.0\n",
      "iteration : 78000 loss : 2.0\n",
      "iteration : 79000 loss : 2.0\n",
      "iteration : 80000 loss : 2.0\n",
      "iteration : 81000 loss : 2.0\n",
      "iteration : 82000 loss : 2.0\n",
      "iteration : 83000 loss : 2.0\n",
      "iteration : 84000 loss : 2.0\n",
      "iteration : 85000 loss : 2.0\n",
      "iteration : 86000 loss : 2.0\n",
      "iteration : 87000 loss : 2.0\n",
      "iteration : 88000 loss : 2.0\n",
      "iteration : 89000 loss : 2.0\n",
      "iteration : 90000 loss : 2.0\n",
      "iteration : 91000 loss : 2.0\n",
      "iteration : 92000 loss : 2.0\n",
      "iteration : 93000 loss : 2.0\n",
      "iteration : 94000 loss : 2.0\n",
      "iteration : 95000 loss : 2.0\n",
      "iteration : 96000 loss : 2.0\n",
      "iteration : 97000 loss : 2.0\n",
      "iteration : 98000 loss : 2.0\n",
      "iteration : 99000 loss : 2.0\n",
      "iteration : 100000 loss : 2.0\n",
      "iteration : 101000 loss : 2.0\n",
      "iteration : 102000 loss : 2.0\n",
      "iteration : 103000 loss : 2.0\n",
      "iteration : 104000 loss : 2.0\n",
      "iteration : 105000 loss : 2.0\n",
      "iteration : 106000 loss : 2.0\n",
      "iteration : 107000 loss : 2.0\n",
      "iteration : 108000 loss : 2.0\n",
      "iteration : 109000 loss : 2.0\n",
      "iteration : 110000 loss : 2.0\n",
      "iteration : 111000 loss : 2.0\n",
      "iteration : 112000 loss : 2.0\n",
      "iteration : 113000 loss : 2.0\n",
      "iteration : 114000 loss : 2.0\n",
      "iteration : 115000 loss : 2.0\n",
      "iteration : 116000 loss : 2.0\n",
      "iteration : 117000 loss : 2.0\n",
      "iteration : 118000 loss : 2.0\n",
      "iteration : 119000 loss : 2.0\n",
      "iteration : 120000 loss : 2.0\n",
      "iteration : 121000 loss : 2.0\n",
      "iteration : 122000 loss : 2.0\n",
      "iteration : 123000 loss : 2.0\n",
      "iteration : 124000 loss : 2.0\n",
      "iteration : 125000 loss : 2.0\n",
      "iteration : 126000 loss : 2.0\n",
      "iteration : 127000 loss : 2.0\n",
      "iteration : 128000 loss : 2.0\n",
      "iteration : 129000 loss : 2.0\n",
      "iteration : 130000 loss : 2.0\n",
      "iteration : 131000 loss : 2.0\n",
      "iteration : 132000 loss : 2.0\n",
      "iteration : 133000 loss : 2.0\n",
      "iteration : 134000 loss : 2.0\n",
      "iteration : 135000 loss : 2.0\n",
      "iteration : 136000 loss : 2.0\n",
      "iteration : 137000 loss : 2.0\n",
      "iteration : 138000 loss : 2.0\n",
      "iteration : 139000 loss : 2.0\n",
      "iteration : 140000 loss : 2.0\n",
      "iteration : 141000 loss : 2.0\n",
      "iteration : 142000 loss : 2.0\n",
      "iteration : 143000 loss : 2.0\n",
      "iteration : 144000 loss : 2.0\n",
      "iteration : 145000 loss : 2.0\n",
      "iteration : 146000 loss : 2.0\n",
      "iteration : 147000 loss : 2.0\n",
      "iteration : 148000 loss : 2.0\n",
      "iteration : 149000 loss : 2.0\n",
      "iteration : 150000 loss : 2.0\n",
      "iteration : 151000 loss : 2.0\n",
      "iteration : 152000 loss : 2.0\n",
      "iteration : 153000 loss : 2.0\n",
      "iteration : 154000 loss : 2.0\n",
      "iteration : 155000 loss : 2.0\n",
      "iteration : 156000 loss : 2.0\n",
      "iteration : 157000 loss : 2.0\n",
      "iteration : 158000 loss : 2.0\n",
      "iteration : 159000 loss : 2.0\n",
      "iteration : 160000 loss : 2.0\n",
      "iteration : 161000 loss : 2.0\n",
      "iteration : 162000 loss : 2.0\n",
      "iteration : 163000 loss : 2.0\n",
      "iteration : 164000 loss : 2.0\n",
      "iteration : 165000 loss : 2.0\n",
      "iteration : 166000 loss : 2.0\n",
      "iteration : 167000 loss : 2.0\n",
      "iteration : 168000 loss : 2.0\n",
      "iteration : 169000 loss : 2.0\n",
      "iteration : 170000 loss : 2.0\n",
      "iteration : 171000 loss : 2.0\n",
      "iteration : 172000 loss : 2.0\n",
      "iteration : 173000 loss : 2.0\n",
      "iteration : 174000 loss : 2.0\n",
      "iteration : 175000 loss : 2.0\n",
      "iteration : 176000 loss : 2.0\n",
      "iteration : 177000 loss : 2.0\n",
      "iteration : 178000 loss : 2.0\n",
      "iteration : 179000 loss : 2.0\n",
      "iteration : 180000 loss : 2.0\n",
      "iteration : 181000 loss : 2.0\n",
      "iteration : 182000 loss : 2.0\n",
      "iteration : 183000 loss : 2.0\n",
      "iteration : 184000 loss : 2.0\n",
      "iteration : 185000 loss : 2.0\n",
      "iteration : 186000 loss : 2.0\n",
      "iteration : 187000 loss : 2.0\n",
      "iteration : 188000 loss : 2.0\n",
      "iteration : 189000 loss : 2.0\n",
      "iteration : 190000 loss : 2.0\n",
      "iteration : 191000 loss : 2.0\n",
      "iteration : 192000 loss : 2.0\n",
      "iteration : 193000 loss : 2.0\n",
      "iteration : 194000 loss : 2.0\n",
      "iteration : 195000 loss : 2.0\n",
      "iteration : 196000 loss : 2.0\n",
      "iteration : 197000 loss : 2.0\n",
      "iteration : 198000 loss : 2.0\n",
      "iteration : 199000 loss : 2.0\n",
      "iteration : 200000 loss : 2.0\n",
      "iteration : 201000 loss : 2.0\n",
      "iteration : 202000 loss : 2.0\n",
      "iteration : 203000 loss : 2.0\n",
      "iteration : 204000 loss : 2.0\n",
      "iteration : 205000 loss : 2.0\n",
      "iteration : 206000 loss : 2.0\n",
      "iteration : 207000 loss : 2.0\n",
      "iteration : 208000 loss : 2.0\n",
      "iteration : 209000 loss : 2.0\n",
      "iteration : 210000 loss : 2.0\n",
      "iteration : 211000 loss : 2.0\n",
      "iteration : 212000 loss : 2.0\n",
      "iteration : 213000 loss : 2.0\n",
      "iteration : 214000 loss : 2.0\n",
      "iteration : 215000 loss : 2.0\n",
      "iteration : 216000 loss : 2.0\n",
      "iteration : 217000 loss : 2.0\n",
      "iteration : 218000 loss : 2.0\n",
      "iteration : 219000 loss : 2.0\n",
      "iteration : 220000 loss : 2.0\n",
      "iteration : 221000 loss : 2.0\n",
      "iteration : 222000 loss : 2.0\n",
      "iteration : 223000 loss : 2.0\n",
      "iteration : 224000 loss : 2.0\n",
      "iteration : 225000 loss : 2.0\n",
      "iteration : 226000 loss : 2.0\n",
      "iteration : 227000 loss : 2.0\n",
      "iteration : 228000 loss : 2.0\n",
      "iteration : 229000 loss : 2.0\n",
      "iteration : 230000 loss : 2.0\n",
      "iteration : 231000 loss : 2.0\n",
      "iteration : 232000 loss : 2.0\n",
      "iteration : 233000 loss : 2.0\n",
      "iteration : 234000 loss : 2.0\n",
      "iteration : 235000 loss : 2.0\n",
      "iteration : 236000 loss : 2.0\n",
      "iteration : 237000 loss : 2.0\n",
      "iteration : 238000 loss : 2.0\n",
      "iteration : 239000 loss : 2.0\n",
      "iteration : 240000 loss : 2.0\n",
      "iteration : 241000 loss : 2.0\n",
      "iteration : 242000 loss : 2.0\n",
      "iteration : 243000 loss : 2.0\n",
      "iteration : 244000 loss : 2.0\n",
      "iteration : 245000 loss : 2.0\n",
      "iteration : 246000 loss : 2.0\n",
      "iteration : 247000 loss : 2.0\n",
      "iteration : 248000 loss : 2.0\n",
      "iteration : 249000 loss : 2.0\n",
      "iteration : 250000 loss : 2.0\n",
      "iteration : 251000 loss : 2.0\n",
      "iteration : 252000 loss : 2.0\n",
      "iteration : 253000 loss : 2.0\n",
      "iteration : 254000 loss : 2.0\n",
      "iteration : 255000 loss : 2.0\n",
      "iteration : 256000 loss : 2.0\n",
      "iteration : 257000 loss : 2.0\n",
      "iteration : 258000 loss : 2.0\n",
      "iteration : 259000 loss : 2.0\n",
      "iteration : 260000 loss : 2.0\n",
      "iteration : 261000 loss : 2.0\n",
      "iteration : 262000 loss : 2.0\n",
      "iteration : 263000 loss : 2.0\n",
      "iteration : 264000 loss : 2.0\n",
      "iteration : 265000 loss : 2.0\n",
      "iteration : 266000 loss : 2.0\n",
      "iteration : 267000 loss : 2.0\n",
      "iteration : 268000 loss : 2.0\n",
      "iteration : 269000 loss : 2.0\n",
      "iteration : 270000 loss : 2.0\n",
      "iteration : 271000 loss : 2.0\n",
      "iteration : 272000 loss : 2.0\n",
      "iteration : 273000 loss : 2.0\n",
      "iteration : 274000 loss : 2.0\n",
      "iteration : 275000 loss : 2.0\n",
      "iteration : 276000 loss : 2.0\n",
      "iteration : 277000 loss : 2.0\n",
      "iteration : 278000 loss : 2.0\n",
      "iteration : 279000 loss : 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 280000 loss : 2.0\n",
      "iteration : 281000 loss : 2.0\n",
      "iteration : 282000 loss : 2.0\n",
      "iteration : 283000 loss : 2.0\n",
      "iteration : 284000 loss : 2.0\n",
      "iteration : 285000 loss : 2.0\n",
      "iteration : 286000 loss : 2.0\n",
      "iteration : 287000 loss : 2.0\n",
      "iteration : 288000 loss : 2.0\n",
      "iteration : 289000 loss : 2.0\n",
      "iteration : 290000 loss : 2.0\n",
      "iteration : 291000 loss : 2.0\n",
      "iteration : 292000 loss : 2.0\n",
      "iteration : 293000 loss : 2.0\n",
      "iteration : 294000 loss : 2.0\n",
      "iteration : 295000 loss : 2.0\n",
      "iteration : 296000 loss : 2.0\n",
      "iteration : 297000 loss : 2.0\n",
      "iteration : 298000 loss : 2.0\n",
      "iteration : 299000 loss : 2.0\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "iterations = []\n",
    "for t in range(300000):\n",
    "    y_hat = np.ceil(relu(x * weight))\n",
    "    error = y_hat - y\n",
    "    \n",
    "\n",
    "    loss = np.square(error).sum()\n",
    "    \n",
    "    if t % 1000 == 0:\n",
    "        iteration = t\n",
    "        print(f'iteration : {iteration} loss : {loss}')\n",
    "\n",
    "        loss_list.append(loss)\n",
    "        iterations.append(iteration)\n",
    "        \n",
    "    grad = 2.0 * error\n",
    "    grad_weight = x.T.dot(grad)\n",
    "    \n",
    "    weight -= lr * grad_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['NanumBarunpenRegular'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARVElEQVR4nO3df4xl5V3H8c9n2S1V+bmdsUV+TWmKtihQGCmmlq5pIstqRBNNRFMqttkY0VCjCWhjqelfhdQ0DSmbtW4WTLNUBRVNqRLTuhoKOFuXZekGWH60XSHdoSitNLYu9+sf55nd2WXuPc/eOTP3fi/vVzI5d849957n4WQ/nPme5zzHESEAwGRaM+oGAABWDiEPABOMkAeACUbIA8AEI+QBYIKtHdWOp6amYmZmZlS7B4CUdu3a9UJETNduP7KQn5mZ0dzc3Kh2DwAp2f7a8WxPuQYAJhghDwATjJAHgAlGyAPABCPkAWCCtYa87bNtf9H2PtuP2b5hiW1s+1O299veY/uSlWkuAOB41AyhPCTp9yPiK7ZPlrTL9v0R8dVF21wl6a3l552Sbi9LAMAItYZ8RDwv6fny+ju290k6U9LikL9a0p3RzFv8oO3TbJ9RPtu5l793SHd8+Vn97/dfWYmvB4AVNTuzXlecX30/07Ic181QtmckvUPSQ8e8daakbyz6/UBZd1TI294sabMknXPOOcfX0kUeeOpbuuULj5fvHPprAGAkfus9bxm/kLd9kqS7JX0oIr597NtLfORVTyOJiK2StkrS7Ozs0E8rOfRKT5J03w3v1tvOOGXYrwGAiVc1usb2OjUB/9mIuGeJTQ5IOnvR72dJem75zVvawv8dOIsHgMFqRtdY0p9L2hcRf9pns3slXVtG2Vwu6aWVqsdL0sITC73kHxAAgAU15Zp3SXqfpEdt7y7r/kjSOZIUEVskfV7SJkn7JX1X0nXdN/WIKOfya8h4ABioZnTNv2npmvvibULS9V01qk1v4UyekAeAgVLe8RpxuCo/0nYAwLhLGfILKNcAwGApQ75XzuRNvQYABkoZ8kdG1wAABkkd8ms4kweAgVKG/JFyzYgbAgBjLmXIDz0fAgC8xqQM+YWUX8PwGgAYKGXIHy7XjLgdADDuUoY8E5QBQJ2cIc/oGgCokjLkKdcAQJ2UIX94dA0pDwADpQz5hXoN5RoAGCxlyPeY1gAAqqQM+WCCMgCokjPky5J7oQBgsJQh3+MZrwBQJWXIB3MNA0CVlCG/gHINAAyWMuR5MhQA1EkZ8lRrAKBOzpAvS07kAWCwnCHPBGUAUCVlyC/U5AEAg6UM+QWcyAPAYClDPpigDACqpAx5JigDgDopQ/7wEErO5AFgoJwhr4VyzYgbAgBjLmXI9ziTB4AqrSFve5vtg7b39nn/VNt/b/sR24/Zvq77Zh6DIZQAUKXmTH67pI0D3r9e0lcj4iJJGyR9wvbrlt+0/kKUagCgRmvIR8ROSS8O2kTSyW5qJyeVbQ9107yl9SIo1QBAhS5q8rdJepuk5yQ9KumGiOgttaHtzbbnbM/Nz88PvcMIhk8CQI0uQv5KSbsl/YikiyXdZvuUpTaMiK0RMRsRs9PT00PvsCnXEPMA0KaLkL9O0j3R2C/pGUk/1sH39tXjVB4AqnQR8l+X9F5Jsv1GST8q6ekOvrc/Mh4Aqqxt28D2DjWjZqZsH5B0s6R1khQRWyR9TNJ224+qyd4bI+KFFWuxKNcAQK3WkI+Ia1ref07Sz3bWogq9XjADJQBUSHnHa4hyDQDUyBnyQbkGAGqkDHlG1wBAnZQhL5HxAFAjZchHhNYweQ0AtEoZ8j2qNQBQJWXIh5igDABq5Ax5zuQBoErOkBdPhQKAGjlDPrjjFQBqJA15yjUAUCNtyHPHKwC0SxnyPco1AFAlZcgzQRkA1MkZ8sHoGgCokTTkKdcAQI2cIS8R8gBQIWfIRzC6BgAqpAx5JigDgDopQ55pDQCgTs6Q58IrAFRJGvKUawCgRs6QZz55AKiSM+RD4ul/ANAuZcj3ImQKNgDQKmXIN9MajLoVADD+coa8GEIJADVyhnwExRoAqJA05CnXAECNnCEvngwFADVaQ972NtsHbe8dsM0G27ttP2b7X7pt4qvxZCgAqFNzJr9d0sZ+b9o+TdKnJf1CRFwg6Ve6aVp/3PEKAHVaQz4idkp6ccAmvybpnoj4etn+YEdt698miaI8AFTooiZ/vqTTbX/J9i7b1/bb0PZm23O25+bn54feYTOf/NAfB4DXjC5Cfq2kSyX9nKQrJf2x7fOX2jAitkbEbETMTk9PD71DyjUAUGdtB99xQNILEfGypJdt75R0kaQnOvjuJTFBGQDU6eJM/u8kvdv2Wts/KOmdkvZ18L19MUEZANRpPZO3vUPSBklTtg9IulnSOkmKiC0Rsc/2FyTtkdST9JmI6DvcsgtMUAYAdVpDPiKuqdjmVkm3dtKiChGiKA8AFRLf8TrqVgDA+MsZ8pRrAKBK0pDnXigAqJEz5MUEZQBQI2XIM0EZANRJGfIRo24BAOSQM+RFuQYAauQMeco1AFAlachzLxQA1MgZ8grKNQBQIWXI93qMkweAGilDvhlcQ8oDQJucIc+ToQCgStKQp1wDADVyhryYoAwAauQM+ZDWpGw5AKyulFHJk6EAoE7KkA+JwTUAUCFlyCuYuwYAaqQM+aZcAwBokzLkQwyhBIAaOUOeCcoAoErOkGeCMgCokjLkez1xKg8AFVKGvCTGyQNAhZQhzwRlAFAnZcj3mKAMAKqkDHkmKAOAOjlDngnKAKBKyqjsMXkNAFRJGfJSUJMHgAqtIW97m+2Dtve2bPeTtl+x/cvdNW9pEWJ0DQBUqDmT3y5p46ANbJ8g6eOS/rGDNrViPnkAqNMa8hGxU9KLLZv9rqS7JR3solFtmKAMAOosuyZv+0xJvyRpS8W2m23P2Z6bn58fep/BfPIAUKWLC6+flHRjRLzStmFEbI2I2YiYnZ6eHnqHvYihPwsAryVrO/iOWUl3uTmznpK0yfahiPjbDr57adzxCgBVlh3yEfHmhde2t0v6hxUNeDU1eco1ANCuNeRt75C0QdKU7QOSbpa0TpIiorUOvxJ4/B8A1GkN+Yi4pvbLIuI3ltWa6v1QrgGAGinveOXJUABQJ2XI90JMXQMAFVKGvIInQwFAjZQh35RrRt0KABh/KUOeJ0MBQJ2UIR9MUAYAVXKGvDiTB4AaOUM+JJPyANAqXchHmZyMiAeAdglDvllyIg8A7fKFfFlyxysAtEsX8j3KNQBQLV3IU64BgHr5Qr4UbBhdAwDt8oU8Z/IAUC1vyFOVB4BW+UK+lGuYoAwA2qUL+R7lGgColi7kj9zxSsoDQJt8IV+WnMkDQLt8Id9rlgyhBIB2+UJe3PEKALXyhXyp1zC6BgDapQv5w3PXUK4BgFbpQp4LrwBQL1/IHx4nT8oDQJuEIc+FVwColS/ky5ITeQBoly/kD4+uIeUBoE26kOfJUABQrzXkbW+zfdD23j7v/7rtPeXnAdsXdd/MIyjXAEC9mjP57ZI2Dnj/GUnviYgLJX1M0tYO2tUXE5QBQL21bRtExE7bMwPef2DRrw9KOmv5zRrUnmbJmTwAtOu6Jv8BSff1e9P2Zttztufm5+eH2gHj5AGgXmchb/tn1IT8jf22iYitETEbEbPT09ND7YcJygCgXmu5pobtCyV9RtJVEfGtLr6zn8NDKNONCwKA1bfsqLR9jqR7JL0vIp5YfpMG63HhFQCqtZ7J294haYOkKdsHJN0saZ0kRcQWSR+R9AZJny518kMRMbtSDWYIJQDUqxldc03L+x+U9MHOWtSCC68AUC9dZZsJygCgXr6QL0tO5AGgXb6QZ4IyAKiWLuSZoAwA6qULeaY1AIB6+UJePMgbAGrlC/mFM/nRNgMAUsgb8pzJA0CrfCFfyjVryHgAaJUu5HtceAWAaulCnidDAUC9fCFflpzJA0C7fCEfDKEEgFoJQ75ZEvEA0C5fyJclc9cAQLt0Id/rLZRrRtwQAEggXcgfvvA60lYAQA75Qp6UB4Bq+UL+8B2vpDwAtMkX8oyuAYBqeUOeM3kAaJUv5JmgDACqpQt5JigDgHrpQj4YXgMA1fKFfFlSrgGAdvlCngnKAKBawpBvlkQ8ALRLG/LcDAUA7dKFfC+YoAwAaqUL+WjfBABQ5At5yjUAUK015G1vs33Q9t4+79v2p2zvt73H9iXdN/OIoFwDANVqzuS3S9o44P2rJL21/GyWdPvym9UfD/IGgHqtIR8ROyW9OGCTqyXdGY0HJZ1m+4yuGvjq9jRLyjUA0K6LmvyZkr6x6PcDZd2r2N5se8723Pz8/FA7e9OpJ2rTT7xJJ524dqjPA8BrSRdJudQp9ZKDYCJiq6StkjQ7OzvUQJlLz12vS89dP8xHAeA1p4sz+QOSzl70+1mSnuvgewEAy9RFyN8r6doyyuZySS9FxPMdfC8AYJlayzW2d0jaIGnK9gFJN0taJ0kRsUXS5yVtkrRf0nclXbdSjQUAHJ/WkI+Ia1reD0nXd9YiAEBn0t3xCgCoR8gDwAQj5AFgghHyADDBfOTB2Ku8Y3te0teG/PiUpBc6bM4o0ZfxRF/GE32Rzo2I6dqNRxbyy2F7LiJmR92OLtCX8URfxhN9OX6UawBgghHyADDBsob81lE3oEP0ZTzRl/FEX45Typo8AKBO1jN5AEAFQh4AJli6kLe90fbj5cHhN426PQtsP2v7Udu7bc+Vdett32/7ybI8fdH2f1j68LjtKxetv7R8z/7ygHSX9Sfa/lxZ/5DtmQ7b/qqHta9W222/v+zjSdvvX6G+fNT2f5Zjs9v2piR9Odv2F23vs/2Y7RvK+nTHZkBfUh0b26+3/bDtR0o//qSsH99jEhFpfiSdIOkpSedJep2kRyS9fdTtKm17VtLUMetukXRTeX2TpI+X128vbT9R0ptLn04o7z0s6afUPHHrPklXlfW/LWlLef2rkj7XYduvkHSJpL2r2XZJ6yU9XZanl9enr0BfPirpD5bYdtz7coakS8rrkyU9Udqc7tgM6EuqY1P2eVJ5vU7SQ5IuH+djku1M/jJJ+yPi6Yj4vqS71DxIfFxdLemO8voOSb+4aP1dEfG9iHhGzVz8l7l5APopEfHlaI7qncd8ZuG7/lrSexf+z79csfTD2lej7VdKuj8iXoyI/5J0v6SNK9CXfsa9L89HxFfK6+9I2qfm+cnpjs2AvvQzln2Jxv+UX9eVn9AYH5NsIV/90PARCEn/ZHuX7c1l3RujPCWrLH+4rO/XjzPL62PXH/WZiDgk6SVJb1iBfixYjbav5vH8Hdt73JRzFv6UTtOX8if7O9ScOaY+Nsf0RUp2bGyfYHu3pINqQnesj0m2kK9+aPgIvCsiLpF0laTrbV8xYNt+/RjUv3Hpe5dtX60+3S7pLZIulvS8pE8so12r3hfbJ0m6W9KHIuLbgzYdom2r2p8l+pLu2ETEKxFxsZrnWV9m+8cHbD7yfmQL+bF9aHhEPFeWByX9jZrS0jfLn2Uqy4Nl8379OFBeH7v+qM/YXivpVNWXJYaxGm1fleMZEd8s/zB7kv5MzbE5ql3H7H9s+mJ7nZpQ/GxE3FNWpzw2S/Ul87GJiP+W9CU1JZPxPSbDXHwY1Y+axxU+reYCxsKF1wvGoF0/JOnkRa8fKAf+Vh19MeaW8voCHX0x5mkduRjz72ou5CxcjNlU1l+voy/G/GXHfZjR0RcrV7ztai4gPaPmItLp5fX6FejLGYte/56aGunY96Xs+05JnzxmfbpjM6AvqY6NpGlJp5XXPyDpXyX9/Dgfk5GG45D/kTepuTL/lKQPj7o9pU3nlQP5iKTHFtqlpo72z5KeLMv1iz7z4dKHx1Wuqpf1s5L2lvdu05G7kl8v6a/UXLh5WNJ5HbZ/h5o/lf9PzdnCB1ar7ZJ+s6zfL+m6FerLX0h6VNIeSffq6GAZ5778tJo/x/dI2l1+NmU8NgP6kurYSLpQ0n+U9u6V9JHV/Lc+TD+Y1gAAJli2mjwA4DgQ8gAwwQh5AJhghDwATDBCHgAmGCEPABOMkAeACfb/K/8a7DJyGIEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(iterations, loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_node가 두개인 신경망\n",
    "\n",
    "weight_ih = np.random.rand(2,2)\n",
    "weight_ho = np.random.rand(2,1)\n",
    "\n",
    "lr = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0 loss : 1.0\n",
      "iteration : 1000 loss : 1.0\n",
      "iteration : 2000 loss : 1.0\n",
      "iteration : 3000 loss : 1.0\n",
      "iteration : 4000 loss : 1.0\n",
      "iteration : 5000 loss : 1.0\n",
      "iteration : 6000 loss : 1.0\n",
      "iteration : 7000 loss : 1.0\n",
      "iteration : 8000 loss : 1.0\n",
      "iteration : 9000 loss : 0.0\n",
      "iteration : 10000 loss : 0.0\n",
      "iteration : 11000 loss : 0.0\n",
      "iteration : 12000 loss : 0.0\n",
      "iteration : 13000 loss : 0.0\n",
      "iteration : 14000 loss : 0.0\n",
      "iteration : 15000 loss : 0.0\n",
      "iteration : 16000 loss : 0.0\n",
      "iteration : 17000 loss : 0.0\n",
      "iteration : 18000 loss : 0.0\n",
      "iteration : 19000 loss : 0.0\n",
      "iteration : 20000 loss : 0.0\n",
      "iteration : 21000 loss : 0.0\n",
      "iteration : 22000 loss : 0.0\n",
      "iteration : 23000 loss : 0.0\n",
      "iteration : 24000 loss : 0.0\n",
      "iteration : 25000 loss : 0.0\n",
      "iteration : 26000 loss : 0.0\n",
      "iteration : 27000 loss : 0.0\n",
      "iteration : 28000 loss : 0.0\n",
      "iteration : 29000 loss : 0.0\n",
      "iteration : 30000 loss : 0.0\n",
      "iteration : 31000 loss : 0.0\n",
      "iteration : 32000 loss : 0.0\n",
      "iteration : 33000 loss : 0.0\n",
      "iteration : 34000 loss : 0.0\n",
      "iteration : 35000 loss : 0.0\n",
      "iteration : 36000 loss : 0.0\n",
      "iteration : 37000 loss : 0.0\n",
      "iteration : 38000 loss : 0.0\n",
      "iteration : 39000 loss : 0.0\n",
      "iteration : 40000 loss : 0.0\n",
      "iteration : 41000 loss : 0.0\n",
      "iteration : 42000 loss : 0.0\n",
      "iteration : 43000 loss : 0.0\n",
      "iteration : 44000 loss : 0.0\n",
      "iteration : 45000 loss : 0.0\n",
      "iteration : 46000 loss : 0.0\n",
      "iteration : 47000 loss : 0.0\n",
      "iteration : 48000 loss : 0.0\n",
      "iteration : 49000 loss : 0.0\n",
      "iteration : 50000 loss : 0.0\n",
      "iteration : 51000 loss : 0.0\n",
      "iteration : 52000 loss : 0.0\n",
      "iteration : 53000 loss : 0.0\n",
      "iteration : 54000 loss : 0.0\n",
      "iteration : 55000 loss : 0.0\n",
      "iteration : 56000 loss : 0.0\n",
      "iteration : 57000 loss : 0.0\n",
      "iteration : 58000 loss : 0.0\n",
      "iteration : 59000 loss : 0.0\n",
      "iteration : 60000 loss : 0.0\n",
      "iteration : 61000 loss : 0.0\n",
      "iteration : 62000 loss : 0.0\n",
      "iteration : 63000 loss : 0.0\n",
      "iteration : 64000 loss : 0.0\n",
      "iteration : 65000 loss : 0.0\n",
      "iteration : 66000 loss : 0.0\n",
      "iteration : 67000 loss : 0.0\n",
      "iteration : 68000 loss : 0.0\n",
      "iteration : 69000 loss : 0.0\n",
      "iteration : 70000 loss : 0.0\n",
      "iteration : 71000 loss : 0.0\n",
      "iteration : 72000 loss : 0.0\n",
      "iteration : 73000 loss : 0.0\n",
      "iteration : 74000 loss : 0.0\n",
      "iteration : 75000 loss : 0.0\n",
      "iteration : 76000 loss : 0.0\n",
      "iteration : 77000 loss : 0.0\n",
      "iteration : 78000 loss : 0.0\n",
      "iteration : 79000 loss : 0.0\n",
      "iteration : 80000 loss : 0.0\n",
      "iteration : 81000 loss : 0.0\n",
      "iteration : 82000 loss : 0.0\n",
      "iteration : 83000 loss : 0.0\n",
      "iteration : 84000 loss : 0.0\n",
      "iteration : 85000 loss : 0.0\n",
      "iteration : 86000 loss : 0.0\n",
      "iteration : 87000 loss : 0.0\n",
      "iteration : 88000 loss : 0.0\n",
      "iteration : 89000 loss : 0.0\n",
      "iteration : 90000 loss : 0.0\n",
      "iteration : 91000 loss : 0.0\n",
      "iteration : 92000 loss : 0.0\n",
      "iteration : 93000 loss : 0.0\n",
      "iteration : 94000 loss : 0.0\n",
      "iteration : 95000 loss : 0.0\n",
      "iteration : 96000 loss : 0.0\n",
      "iteration : 97000 loss : 0.0\n",
      "iteration : 98000 loss : 0.0\n",
      "iteration : 99000 loss : 0.0\n",
      "iteration : 100000 loss : 0.0\n",
      "iteration : 101000 loss : 0.0\n",
      "iteration : 102000 loss : 0.0\n",
      "iteration : 103000 loss : 0.0\n",
      "iteration : 104000 loss : 0.0\n",
      "iteration : 105000 loss : 0.0\n",
      "iteration : 106000 loss : 0.0\n",
      "iteration : 107000 loss : 0.0\n",
      "iteration : 108000 loss : 0.0\n",
      "iteration : 109000 loss : 0.0\n",
      "iteration : 110000 loss : 0.0\n",
      "iteration : 111000 loss : 0.0\n",
      "iteration : 112000 loss : 0.0\n",
      "iteration : 113000 loss : 0.0\n",
      "iteration : 114000 loss : 0.0\n",
      "iteration : 115000 loss : 0.0\n",
      "iteration : 116000 loss : 0.0\n",
      "iteration : 117000 loss : 0.0\n",
      "iteration : 118000 loss : 0.0\n",
      "iteration : 119000 loss : 0.0\n",
      "iteration : 120000 loss : 0.0\n",
      "iteration : 121000 loss : 0.0\n",
      "iteration : 122000 loss : 0.0\n",
      "iteration : 123000 loss : 0.0\n",
      "iteration : 124000 loss : 0.0\n",
      "iteration : 125000 loss : 0.0\n",
      "iteration : 126000 loss : 0.0\n",
      "iteration : 127000 loss : 0.0\n",
      "iteration : 128000 loss : 0.0\n",
      "iteration : 129000 loss : 0.0\n",
      "iteration : 130000 loss : 0.0\n",
      "iteration : 131000 loss : 0.0\n",
      "iteration : 132000 loss : 0.0\n",
      "iteration : 133000 loss : 0.0\n",
      "iteration : 134000 loss : 0.0\n",
      "iteration : 135000 loss : 0.0\n",
      "iteration : 136000 loss : 0.0\n",
      "iteration : 137000 loss : 0.0\n",
      "iteration : 138000 loss : 0.0\n",
      "iteration : 139000 loss : 0.0\n",
      "iteration : 140000 loss : 0.0\n",
      "iteration : 141000 loss : 0.0\n",
      "iteration : 142000 loss : 0.0\n",
      "iteration : 143000 loss : 0.0\n",
      "iteration : 144000 loss : 0.0\n",
      "iteration : 145000 loss : 0.0\n",
      "iteration : 146000 loss : 0.0\n",
      "iteration : 147000 loss : 0.0\n",
      "iteration : 148000 loss : 0.0\n",
      "iteration : 149000 loss : 0.0\n",
      "iteration : 150000 loss : 0.0\n",
      "iteration : 151000 loss : 0.0\n",
      "iteration : 152000 loss : 0.0\n",
      "iteration : 153000 loss : 0.0\n",
      "iteration : 154000 loss : 0.0\n",
      "iteration : 155000 loss : 0.0\n",
      "iteration : 156000 loss : 0.0\n",
      "iteration : 157000 loss : 0.0\n",
      "iteration : 158000 loss : 0.0\n",
      "iteration : 159000 loss : 0.0\n",
      "iteration : 160000 loss : 0.0\n",
      "iteration : 161000 loss : 0.0\n",
      "iteration : 162000 loss : 0.0\n",
      "iteration : 163000 loss : 0.0\n",
      "iteration : 164000 loss : 0.0\n",
      "iteration : 165000 loss : 0.0\n",
      "iteration : 166000 loss : 0.0\n",
      "iteration : 167000 loss : 0.0\n",
      "iteration : 168000 loss : 0.0\n",
      "iteration : 169000 loss : 0.0\n",
      "iteration : 170000 loss : 0.0\n",
      "iteration : 171000 loss : 0.0\n",
      "iteration : 172000 loss : 0.0\n",
      "iteration : 173000 loss : 0.0\n",
      "iteration : 174000 loss : 0.0\n",
      "iteration : 175000 loss : 0.0\n",
      "iteration : 176000 loss : 0.0\n",
      "iteration : 177000 loss : 0.0\n",
      "iteration : 178000 loss : 0.0\n",
      "iteration : 179000 loss : 0.0\n",
      "iteration : 180000 loss : 0.0\n",
      "iteration : 181000 loss : 0.0\n",
      "iteration : 182000 loss : 0.0\n",
      "iteration : 183000 loss : 0.0\n",
      "iteration : 184000 loss : 0.0\n",
      "iteration : 185000 loss : 0.0\n",
      "iteration : 186000 loss : 0.0\n",
      "iteration : 187000 loss : 0.0\n",
      "iteration : 188000 loss : 0.0\n",
      "iteration : 189000 loss : 0.0\n",
      "iteration : 190000 loss : 0.0\n",
      "iteration : 191000 loss : 0.0\n",
      "iteration : 192000 loss : 0.0\n",
      "iteration : 193000 loss : 0.0\n",
      "iteration : 194000 loss : 0.0\n",
      "iteration : 195000 loss : 0.0\n",
      "iteration : 196000 loss : 0.0\n",
      "iteration : 197000 loss : 0.0\n",
      "iteration : 198000 loss : 0.0\n",
      "iteration : 199000 loss : 0.0\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "iterations = []\n",
    "for t in range(200000):\n",
    "    hidden = relu(x * weight_ih)\n",
    "    y_hat = np.ceil(relu(hidden.dot(weight_ho)))\n",
    "    \n",
    "    error = y_hat - y\n",
    "    \n",
    "    loss = np.square(error).sum()\n",
    "\n",
    "    if t % 1000 == 0:    \n",
    "        iteration = t\n",
    "        print(f'iteration : {t} loss : {loss}')\n",
    "        \n",
    "        loss_list.append(loss)\n",
    "        iterations.append(iteration)\n",
    "    \n",
    "    grad_pred = 2.0 * error\n",
    "    grad_weight_ho = hidden.T.dot(grad_pred)\n",
    "    grad_weight_ih = x.T.dot(hidden)\n",
    "    \n",
    "    weight_ih -= lr * grad_weight_ih\n",
    "    weight_ho -= lr* grad_weight_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff5d9da3a90>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATAElEQVR4nO3dYYxcV3mH8eddm6QCAknwgoxjx05laI2UQLKYoDaUqgLspDSirdQYVGgKsqImFbSqRFBUioT6ASIqRAkYF1kRFcW0Ii1ua5q2iAapiDYOTUwccNiaQIxDsoEWKFSkxm8/3OtkPN713t2dnVnP+/yk0czcOTvz+s74v2fPPXNuZCaSpPE0MeoCJEnLx5CXpDFmyEvSGDPkJWmMGfKSNMZWj+qF16xZkxs3bhzVy0vSWemee+55PDMnu7YfWchv3LiRAwcOjOrlJemsFBHfWEh7h2skaYwZ8pI0xgx5SRpjhrwkjTFDXpLG2LwhHxF7IuKxiLh/jscjIj4QEdMRcTAiLh98mZKkxejSk78d2HaGx7cDm9vLTuDDSy9LkjQI886Tz8zPR8TGMzS5FvhYNmsWfzEizo+ItZn5yIBqPMXhb/+Avz94bEE/87RVE7zhyou58BnnLEdJkrRiDeLLUOuAh3vuH223nRbyEbGTprfPhg0bFvVi04/9D3/6uenO7U8ul7/mvHPZsXVxrylJZ6tBhHzMsm3WM5Fk5m5gN8DU1NSizlZyzaVruebSazq3n/nBj3npH/8zx094chRJ9Qxids1RYH3P/YuAhY2nLKOJ9leQZ8CSVNEgQn4f8MZ2ls2VwPeWazx+MSaiSfkT9uQlFTTvcE1EfAJ4JbAmIo4CfwQ8DSAzdwH7gauBaeBHwPXLVexiPBnyZrykgrrMrtkxz+MJ3DiwigYs2r9VTjhcI6mgsf/G68mevBkvqaICId9c25OXVFGBkHdMXlJdYx/yYU9eUmFjH/JPjckb8pLqKRPyDtdIqqhAyDfXDtdIqmjsQz7syUsqbOxDHprevGPykioqEvLhcI2kkgqF/KirkKThKxHyER54lVRTiZCfiHDtGkklFQl515OXVFORkHdMXlJNJULeMXlJVZUI+YmJcJ68pJJqhLzDNZKKKhLyDtdIqqlEyIc9eUlFlQh5166RVFWRkPfLUJJqKhPyjslLqqhEyDfz5EddhSQNX4mQb4ZrTHlJ9RQJeadQSqqpSMg7hVJSTSVC3rVrJFVVIuSdQimpqjIhb09eUkUlQt7hGklVdQr5iNgWEYcjYjoibp7l8WdHxN9GxH0RcSgirh98qYvngVdJVc0b8hGxCrgN2A5sAXZExJa+ZjcCD2TmZcArgfdFxDkDrnXRJiZcu0ZSTV168luB6cw8kplPAHuBa/vaJHBeRATwTOC7wPGBVroE9uQlVdUl5NcBD/fcP9pu6/VB4GeBY8CXgbdm5on+J4qInRFxICIOzMzMLLLkhQsPvEoqqkvIxyzb+hPzNcC9wPOBFwMfjIhnnfZDmbszcyozpyYnJxdc7GJNuHaNpKK6hPxRYH3P/Ytoeuy9rgfuyMY08HXgZwZT4tK5do2kqrqE/N3A5ojY1B5MvQ7Y19fmm8AvAUTE84AXAkcGWehSuHaNpKpWz9cgM49HxE3AncAqYE9mHoqIG9rHdwHvBm6PiC/TDO+8PTMfX8a6FyQiOHHaEQJJGn/zhjxAZu4H9vdt29Vz+xjw6sGWNjj25CVVVeIbr65dI6mqMiFvT15SRSVC3rVrJFVVIuT9xqukqoqEvGvXSKqpSMjbk5dUU4mQd0xeUlVFQt6evKSaSoS8Y/KSqioS8s6Tl1RToZAfdRWSNHwlQt4Dr5KqKhHyrl0jqaoiIW9PXlJNRULeA6+SaioR8p40RFJVJULeefKSqioS8k6hlFRTjZCf8MCrpJpKhLxr10iqqkTIOyYvqaoiIe8USkk1FQr5UVchScNXIuRdu0ZSVSVC3rVrJFVVJOTtyUuqqUjIe+BVUk0lQt558pKqKhHyzpOXVFWRkLcnL6mmTiEfEdsi4nBETEfEzXO0eWVE3BsRhyLirsGWuTQeeJVU1er5GkTEKuA24FXAUeDuiNiXmQ/0tDkf+BCwLTO/GRHPXa6CFyOcQimpqC49+a3AdGYeycwngL3AtX1tXg/ckZnfBMjMxwZb5tJMRACOy0uqp0vIrwMe7rl/tN3W6wXABRHxLxFxT0S8cbYnioidEXEgIg7MzMwsruJFmGgy3nF5SeV0CfmYZVt/XK4GrgCuAV4D/GFEvOC0H8rcnZlTmTk1OTm54GIXa6JNecflJVUz75g8Tc99fc/9i4Bjs7R5PDN/CPwwIj4PXAY8OJAqlyie7Mkb8pJq6dKTvxvYHBGbIuIc4DpgX1+bTwNXRcTqiHg68DLgK4MtdfGeGpMfcSGSNGTz9uQz83hE3ATcCawC9mTmoYi4oX18V2Z+JSL+ATgInAA+mpn3L2fhCzFhT15SUV2Ga8jM/cD+vm27+u7fCtw6uNIG52RP3gOvkqop8Y3XCA+8SqqpRMifHK7JE6OtQ5KGrUjI25OXVFORkG+uDXlJ1ZQI+fDAq6SiSoS8a9dIqqpIyDfX9uQlVVMk5D3wKqmmEiHv2jWSqioR8q5dI6mqGiHf/ivtyUuqpkbIO4VSUlElQt61ayRVVSLkn1y7xpCXVEyRkHe4RlJNRUK+uXa4RlI1JUL+yTF5lxqWVEyJkPcbr5KqKhHy7WiNX4aSVE6JkPfLUJKqKhHyzpOXVFWJkHcKpaSqioR8c+2XoSRVUyTk7clLqqlEyLuevKSqSoS88+QlVVUq5M14SdUUCfnm2p68pGpKhHx44FVSUSVC3p68pKqKhPzJMXlDXlItnUI+IrZFxOGImI6Im8/Q7qUR8ZOI+PXBlbh0Ey41LKmoeUM+IlYBtwHbgS3AjojYMke79wB3DrrIpXKevKSquvTktwLTmXkkM58A9gLXztLud4FPAY8NsL6B8BuvkqrqEvLrgId77h9ttz0pItYBrwN2nemJImJnRByIiAMzMzMLrXXRTi417Ji8pGq6hHzMsq0/Ld8PvD0zf3KmJ8rM3Zk5lZlTk5OTXWtcMnvykqpa3aHNUWB9z/2LgGN9baaAve189DXA1RFxPDP/ZiBVLpFTKCVV1SXk7wY2R8Qm4FvAdcDrextk5qaTtyPiduDvVkrAgycNkVTXvCGfmccj4iaaWTOrgD2ZeSgibmgfP+M4/Erg2jWSqurSkycz9wP7+7bNGu6Z+VtLL2uwHK6RVFWpb7x64FVSNSVC3i9DSaqqRMi7do2kqkqFvMM1kqopEvLNtcM1kqopEfLhFEpJRZUI+ZM9ecfkJVVTJOQdk5dUU7GQN+Ul1VIi5KP9V9qTl1RNiZB3nrykqoqEfHPtcI2kaoqEvAdeJdVUIuRdu0ZSVSVC3vXkJVVVKuRPOF4jqZgiId9cm/GSqikR8p7jVVJVJUIemt688+QlVVMo5MPhGknlFAt5U15SLWVCPsIDr5LqKRPyExGOyUsqp1DIO7tGUj2FQt4Dr5LqKRPyYU9eUkFlQn5iIly7RlI5dULeKZSSCioU8g7XSKqnTMiDB14l1dMp5CNiW0QcjojpiLh5lsffEBEH28sXIuKywZe6NK5dI6mieUM+IlYBtwHbgS3AjojY0tfs68AvZOalwLuB3YMudKkmIjhxYtRVSNJwdenJbwWmM/NIZj4B7AWu7W2QmV/IzP9q734RuGiwZS6dY/KSKuoS8uuAh3vuH223zeXNwGdmeyAidkbEgYg4MDMz073KAQi/DCWpoC4hH7NsmzUuI+IXaUL+7bM9npm7M3MqM6cmJye7VzkAExOOyUuqZ3WHNkeB9T33LwKO9TeKiEuBjwLbM/M7gylvcJwnL6miLj35u4HNEbEpIs4BrgP29TaIiA3AHcBvZuaDgy9z6Vy7RlJF8/bkM/N4RNwE3AmsAvZk5qGIuKF9fBfwTuA5wIfa86kez8yp5St74Vy7RlJFXYZryMz9wP6+bbt6br8FeMtgSxusZj35UVchScNV5huvTqGUVFGhkPfAq6R6yoS88+QlVVQm5F27RlJFhULenrykegqFvAdeJdVTJuQdk5dUUZmQd0xeUkWFQt4plJLqqRXynjREUjFlQt61ayRVVCbkXbtGUkV1Qn7CnrykeuqEvAdeJRVUJuSdJy+pojIh7zx5SRUVCnl78pLqKRTykJjykmopE/Lhl6EkFVQm5F2FUlJFhULeL0NJqqdUyNuTl1RNmZB37RpJFZUJeYdrJFVUKOTtyUuqp1DI+2UoSfWUCfnwwKukgsqEfLN2zairkKThKhTy9uQl1VMn5D1piKSCyoS868lLqqhTyEfEtog4HBHTEXHzLI9HRHygffxgRFw++FKXxvXkJVU0b8hHxCrgNmA7sAXYERFb+pptBza3l53Ahwdc55I5hVJSRas7tNkKTGfmEYCI2AtcCzzQ0+Za4GPZdJW/GBHnR8TazHxk4BUv0kQE//2jJ3jVn9w16lIkFfcbL13PW666ZCiv1SXk1wEP99w/CrysQ5t1wCkhHxE7aXr6bNiwYaG1LslrL3s+Mz/4sScOkTRya5557tBeq0vIxyzb+pOySxsyczewG2BqamqoaXvFxRdwxcUXDPMlJWnkuhx4PQqs77l/EXBsEW0kSUPWJeTvBjZHxKaIOAe4DtjX12Yf8MZ2ls2VwPdW0ni8JFU173BNZh6PiJuAO4FVwJ7MPBQRN7SP7wL2A1cD08CPgOuXr2RJUlddxuTJzP00Qd67bVfP7QRuHGxpkqSlKvONV0mqyJCXpDFmyEvSGDPkJWmMxagW7YqIGeAbi/zxNcDjAyxnkFZqbda1MCu1Lli5tVnXwiy2roszc7Jr45GF/FJExIHMnBp1HbNZqbVZ18Ks1Lpg5dZmXQszrLocrpGkMWbIS9IYO1tDfveoCziDlVqbdS3MSq0LVm5t1rUwQ6nrrByTlyR1c7b25CVJHRjykjTOMvOsugDbgMM0K17evAzPvx74HPAV4BDw1nb7u4BvAfe2l6t7fuYdbT2Hgdf0bL8C+HL72Ad4anjsXOCT7fZ/AzYuoL6H2ue8FzjQbrsQ+Cfga+31BcOsDXhhz365F/g+8LZR7DNgD/AYcH/PtqHsH+BN7Wt8DXhTx9puBb4KHAT+Gji/3b4R+N+efbdruWqbo66hvHeLqOuTPTU9BNw7gv01V0asiM/ZaZ+7QYfkcl5oljr+T+AS4BzgPmDLgF9jLXB5e/s84EGaE5i/C/iDWdpvaes4F9jU1reqfezfgZfTnDnrM8D2dvvvnPwQ0qzP/8kF1PcQsKZv23tpf+EBNwPvGUVtPe/Rt4GLR7HPgFcAl3NqMCz7/qH5D36kvb6gvX1Bh9peDaxub7+np7aNve36nmegtc1R17K/d4upq6+W9wHvHMH+misjVsTn7LR//0JDcJSXdmfc2XP/HcA7lvk1Pw286gwf+lNqoFl3/+XtB+GrPdt3AB/pbdPeXk3zrbfoWM9DnB7yh4G1PR/Aw6Oorf2ZVwP/2t4eyT6j7z/8MPZPb5v2sY8AO+arre+x1wEfP1O75aptln227O/dYurq2R4055XePIr91fcaJzNixXzOei9n25j8XCcMXxYRsRF4Cc2fSwA3RcTBiNgTESdPGDtXTeva27PV+uTPZOZx4HvAczqWlcA/RsQ97YnRAZ6X7Zm42uvnjqg2aHodn+i5vxL22TD2zyA+m79N05s7aVNE/EdE3BURV/W8/rBqW+73bin77Crg0cz8Ws+2oe+vvoxYkZ+zsy3kO50wfCAvFPFM4FPA2zLz+8CHgZ8GXgw8QvOn4plqOlOtS/l3/FxmXg5sB26MiFecoe1Qa2tPD/krwF+1m1bKPpvLIOtYUn0RcQtwHPh4u+kRYENmvgT4feAvIuJZQ6xtGO/dUvbZDk7tTAx9f82SEXMZ6T4720J+KCcMj4in0bx5H8/MOwAy89HM/ElmngD+DNg6T01H29uz1frkz0TEauDZwHe71JaZx9rrx2gO1G0FHo2Ite3zraU5WDX02mh+8XwpMx9ta1wR+4zh7J9FfzYj4k3ALwNvyPZv8Mz8cWZ+p719D8047guGVduQ3rtF7bP2OX6V5sDkyXqHur9mywhW6ufsTGM5K+1CMzZ1hObgxckDry8a8GsE8DHg/X3b1/bc/j1gb3v7RZx6UOUITx1UuRu4kqcOqlzdbr+RUw+q/GXH2p4BnNdz+ws0s41u5dQDPu8ddm1t+73A9aPeZ5w+vrzs+4fmQNjXaQ6GXdDevrBDbduAB4DJvnaTPbVcQjPT5cLlqm2Wupb9vVtMXT377K5R7S/mzogV8zk7pa7FhuGoLjQnDH+Q5jf1Lcvw/D9P8+fPQXqmjwF/TjPV6SCwr+8/wS1tPYdpj46326eA+9vHPshT06N+imZIY5rm6PolHWu7pP2w3EczdeuWdvtzgM/STKn6bN8Hcli1PR34DvDsnm1D32c0f8I/AvwfTa/nzcPaPzRj6tPt5fqOtU3TjLGeMvUP+LX2Pb4P+BLw2uWqbY66hvLeLbSudvvtwA19bYe5v+bKiBXxOeu/uKyBJI2xs21MXpK0AIa8JI0xQ16SxpghL0ljzJCXpDFmyEvSGDPkJWmM/T802jbLJYvqSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iterations, loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
